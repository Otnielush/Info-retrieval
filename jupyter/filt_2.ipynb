{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# spacy english model (large)\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('run to the sun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False | 0.8905416137386603\n",
      "cat True 6.6808186 False | 0.8196947233396737\n",
      "horse True 6.760544 False | 0.7755440202256019\n",
      "ball True 6.874591 False | 0.6057424500868062\n",
      "Similarity: 0.80168545\n",
      "0.6246275901794434\n"
     ]
    }
   ],
   "source": [
    "words = 'dog cat horse ball'\n",
    "tokens = nlp(words)\n",
    "\n",
    "for token in tokens:\n",
    "    # Printing the following attributes of each token.\n",
    "    # text: the word string, has_vector: if it contains\n",
    "    # a vector representation in the model, \n",
    "    # vector_norm: the algebraic norm of the vector,\n",
    "    # is_oov: if the word is out of vocabulary.\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov,'|',token.similarity(tokens))\n",
    "  \n",
    "token1, token2 = tokens[0], tokens[1]\n",
    "  \n",
    "print(\"Similarity:\", token1.similarity(token2))\n",
    "print(cosineSimilarity(tokens[0].vector, tokens[2].vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41217241988421455"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.similarity(nlp('creature'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser_l3 import you_parse\n",
    "from filter_2 import filter_2\n",
    "from yt_search_l1 import search_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = search_1('how to brake wall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [x['id'] for x in s_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing donef 5\n"
     ]
    }
   ],
   "source": [
    "yt_obs = you_parse(ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_2(search_sentence, yt_objects):\n",
    "    # may be: % of relevance; recomendation in which part more relevance for search\n",
    "    predictions = []\n",
    "\n",
    "    tokens = nlp(search_sentence)\n",
    "\n",
    "    # parsing info from yt_objects\n",
    "    y_keywords = []\n",
    "    y_views = []\n",
    "    y_title = []\n",
    "    y_author = []\n",
    "    y_description = []   # replace '\\n'\n",
    "    y_length = []\n",
    "    y_publish_date = []\n",
    "    y_rating = []\n",
    "    spacy_similarity = []\n",
    "\n",
    "    for i, obj in enumerate(yt_objects):\n",
    "        y_keywords.append(obj.keywords) # list\n",
    "        y_views.append(obj.views)\n",
    "        y_title.append(obj.title)\n",
    "        y_author.append(obj.author)\n",
    "        y_description.append(obj.description.replace('\\n', ' '))\n",
    "        y_length.append(obj.length)\n",
    "        y_publish_date.append(obj.publish_date)  # datetime\n",
    "        y_rating.append(obj.rating)\n",
    "\n",
    "            # We can add here weights\n",
    "        ss = tokens.similarity(nlp(' '.join(y_keywords[-1])))\n",
    "        ss += tokens.similarity(nlp(y_title[-1]))\n",
    "        ss += tokens.similarity(nlp(y_author[-1]))\n",
    "        ss += tokens.similarity(nlp(y_description[-1]))\n",
    "\n",
    "        spacy_similarity.append(ss)\n",
    "        obj.similarity = ss\n",
    "        print(obj.author)\n",
    "        print(ss)\n",
    "\n",
    "\n",
    "    return yt_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowe's Home Improvement\n",
      "3.059274095651319\n",
      "HouseImprovements\n",
      "2.3828411050632523\n",
      "AllYouWannaSee Official\n",
      "2.6295460970384528\n",
      "Manoj Jangid InteriorLane\n",
      "2.264071499328746\n",
      "Our Build\n",
      "2.8638803542532822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-4e850ed002b2>:31: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  ss += tokens.similarity(nlp(y_author[-1]))\n"
     ]
    }
   ],
   "source": [
    "yt_obs_n = filter_2('how to brake wall', yt_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.059274095651319"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_obs_n[0].similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.059274095651319\n",
      "2.8638803542532822\n",
      "2.6295460970384528\n",
      "2.3828411050632523\n",
      "2.264071499328746\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(yt_obs_n, key=lambda x: x.similarity, reverse=True):\n",
    "    print(x.similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
